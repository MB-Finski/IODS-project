<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Linear regression</title>

<script src="site_libs/jquery-1.12.4/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/lumen.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="site_libs/htmlwidgets-1.5.2/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.16/datatables.js"></script>
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 54px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h2 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h3 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h4 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h5 {
  padding-top: 59px;
  margin-top: -59px;
}
.section h6 {
  padding-top: 59px;
  margin-top: -59px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">My IODS project page</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
    Introduction
  </a>
</li>
<li>
  <a href="chapter2.html">
    <span class="fa fa-info"></span>
     
    Linear regression
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Linear regression</h1>

</div>


<p>In the following exercise we inspect an example data set for linear correlations using R. First we inspect the data set and then we select three most promising variables for analysis with multiple linear regression.</p>
<p>You can focus on specific parts of the data analysis by topic below.</p>
<div id="section" class="section level1 tabset tabset-fade tabset-pills">
<h1></h1>
<div id="data-description" class="section level2">
<h2>1: Data description</h2>
<div id="description-of-data" class="section level3">
<h3>Description of data</h3>
<p>The data set used this exercise has been previously parsed from <a href="http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt">this</a> file using an R script available <a href="https://github.com/MB-Finski/IODS-project/data">here</a>.</p>
<p>The data consists of students who underwent a statistics course in 2014 to 2015. Their global attitude toward statistics and learning approaches were recorded with the aid of surveys. Finally the exam points for the course were also recorded for each student. A more exhaustive metadata is available <a href="https://www.mv.helsinki.fi/home/kvehkala/JYTmooc/JYTOPKYS3-meta.txt">here</a>.</p>
<p>For an explanation of the individual variables, please, refer to the following:</p>
<table>
<colgroup>
<col width="18%" />
<col width="81%" />
</colgroup>
<thead>
<tr class="header">
<th>Variable name</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><em>gender</em></td>
<td>Gender of the student encoded as “M” or “F”</td>
</tr>
<tr class="even">
<td><em>points</em></td>
<td>Points from the course exam</td>
</tr>
<tr class="odd">
<td><em>attitude</em></td>
<td>Global attitude towards statistics on a scale of 1-5 (higher = better)</td>
</tr>
<tr class="even">
<td><em>age</em></td>
<td>Age of the student</td>
</tr>
<tr class="odd">
<td><em>deep</em></td>
<td>Deep learning approach on a scale of 1-5 (higher = more deep learning approach)</td>
</tr>
<tr class="even">
<td><em>stra</em></td>
<td>Strategic learning approach on a scale of 1-5 (higher = more strategic learning approach)</td>
</tr>
<tr class="odd">
<td><em>surf</em></td>
<td>Superficial learning approach on a scale of 1-5 (higher = more superficial learning approach)</td>
</tr>
</tbody>
</table>
<hr />
</div>
<div id="exploring-the-data-table-structure" class="section level3">
<h3>Exploring the data table structure</h3>
<p>Let’s explore the data set using the str() function:</p>
<pre class="r"><code>#Read the table from the source file
analysisDataset = read.table(&quot;https://raw.githubusercontent.com/MB-Finski/IODS-project/master/data/learning2014.txt&quot;)

#Print out the basic structure and dimensions of the dataset
#Please note, that dim() is redundant here as str() already prints out the table dimensions
str(analysisDataset)</code></pre>
<pre><code>## &#39;data.frame&#39;:    166 obs. of  7 variables:
##  $ gender  : chr  &quot;F&quot; &quot;M&quot; &quot;F&quot; &quot;M&quot; ...
##  $ points  : int  25 12 24 10 22 21 21 31 24 26 ...
##  $ attitude: num  3.7 3.1 2.5 3.5 3.7 3.8 3.5 2.9 3.8 2.1 ...
##  $ age     : int  53 55 49 53 49 38 50 37 37 42 ...
##  $ deep    : num  3.58 2.92 3.5 3.5 3.67 ...
##  $ stra    : num  3.38 2.75 3.62 3.12 3.62 ...
##  $ surf    : num  2.58 3.17 2.25 2.25 2.83 ...</code></pre>
<p>As you can see the data consists of 166 observations with 7 variables.</p>
<hr />
</div>
<div id="interactive-data-table" class="section level3">
<h3>Interactive data table</h3>
<p>Below you can explore the whole data set interactively. The code is left visible for the purposes of this course, only.</p>
<pre class="r"><code>#Draw an interactive data table
library(DT)
datatable(analysisDataset,options = list(columnDefs = list(list(
  targets = 1:7,
  render = JS(
    &quot;function(data, type, row, meta) {&quot;,
    &quot;return type === &#39;display&#39; &amp;&amp; data.toString().length &gt; 5 ?&quot;,
    &quot;&#39;&lt;span title=\&quot;&#39; + data.toString() + &#39;\&quot;&gt;&#39; + data.toString().substr(0, 5) + &#39;...&lt;/span&gt;&#39; : data.toString();&quot;,
    &quot;}&quot;)
  ))),callback = JS(&#39;table.page(0).draw(false);&#39;))</code></pre>
<div id="htmlwidget-722e94436591adcfef13" style="width:100%;height:auto;" class="datatables html-widget"></div>
<script type="application/json" data-for="htmlwidget-722e94436591adcfef13">{"x":{"filter":"none","data":[["1","2","3","4","5","6","7","8","9","10","11","12","13","14","15","17","18","19","20","21","22","23","24","25","26","27","28","30","31","32","33","34","35","36","37","38","39","40","41","42","43","44","45","46","47","48","49","50","51","52","53","54","55","56","57","58","59","60","61","62","63","64","65","66","67","68","70","71","72","73","74","75","77","78","79","80","81","82","83","84","85","86","87","88","89","91","92","93","95","96","97","98","99","100","101","103","105","107","108","109","110","111","112","113","114","115","116","117","118","119","120","121","122","123","124","125","128","129","130","131","132","133","134","136","137","138","139","140","141","142","143","146","147","148","149","150","151","152","153","154","155","156","157","158","159","160","161","162","163","164","165","166","168","169","170","172","173","175","176","177","178","179","180","181","182","183"],["F","M","F","M","M","F","M","F","M","F","M","F","F","F","M","F","F","F","M","F","M","M","F","F","F","F","M","F","F","M","M","F","F","F","M","F","M","M","M","M","F","F","M","F","F","F","M","F","F","F","M","M","M","F","F","F","F","F","M","M","F","F","F","F","F","M","F","F","F","F","F","M","M","M","F","F","M","M","M","M","F","F","M","M","M","F","F","M","F","F","F","M","F","F","F","M","M","M","F","M","F","F","M","F","F","F","F","F","F","F","F","F","F","M","F","M","F","F","M","F","F","F","M","M","F","F","F","F","F","F","F","M","F","F","M","F","F","F","F","F","F","F","M","F","F","F","F","M","F","M","F","F","F","F","M","F","F","F","F","F","F","F","M","F","F","M"],[25,12,24,10,22,21,21,31,24,26,31,31,23,25,21,31,20,22,9,24,28,30,24,9,26,32,32,33,29,30,19,23,19,12,10,11,20,26,31,20,23,12,24,17,29,23,28,31,23,25,18,19,22,25,21,9,28,25,29,33,33,25,18,22,17,25,28,22,26,11,29,22,21,28,33,16,31,22,31,23,26,12,26,31,19,30,12,17,18,19,21,24,28,17,18,17,23,26,28,31,27,25,23,21,27,28,23,21,25,11,19,24,28,21,24,24,20,19,30,22,16,16,19,30,23,19,18,28,21,19,27,24,21,20,28,12,21,28,31,18,25,19,21,16,7,21,17,22,18,25,24,23,23,26,12,32,22,20,21,23,20,28,31,18,30,19],[3.7,3.1,2.5,3.5,3.7,3.8,3.5,2.9,3.8,2.1,3.9,3.8,2.4,3,2.6,4.1,2.6,2.6,1.7,2.7,3.9,3.4,2.7,2.3,3.7,4.4,4.1,3.7,2.5,3,3.4,3.2,2,2.4,4.2,1.6,3.1,3.8,3.8,3.3,1.7,2.5,3.2,3.5,3.2,4.2,3.1,3.9,1.9,2.1,2.5,3.2,3.2,2.6,2.3,3.8,2.8,3.3,4.8,4,4,4.7,2.3,3.1,2.7,4.1,3.4,2.5,2.1,1.4,1.9,3.7,3.2,2.8,4.1,2.5,2.8,3.8,3.1,3.5,3.6,2.6,4.4,4.5,3.2,3.9,2.5,3.3,3.3,3,2.9,3.3,3.3,3.5,3.6,3.7,4.2,3.2,5,4.7,3.6,3.6,2.9,3.5,4,3.5,3.2,2.6,2,2.7,3.2,3.3,3.9,3.3,3,3.7,2.5,2.9,3.9,3.6,2.9,2.1,3.1,4,3.1,2.3,2.8,3.7,2.6,2.4,3,2.8,2.9,2.4,3.1,1.9,2,3.8,3.4,3.7,2.9,2.3,4.1,2.7,3.5,3.4,3.2,3.3,3.3,3.5,3.2,3.1,2.8,1.7,1.9,3.5,2.4,2.1,2.9,1.9,2,4.2,4.1,3.7,3.6,1.8],[53,55,49,53,49,38,50,37,37,42,37,34,34,34,35,33,32,44,29,30,27,29,31,37,26,26,30,33,33,28,26,27,25,31,20,39,38,24,26,25,30,25,30,48,24,40,25,23,25,23,27,25,23,23,23,45,22,23,21,21,21,21,26,25,26,21,23,22,22,22,23,22,23,24,22,23,22,20,22,21,22,23,21,22,29,29,21,28,21,30,21,23,21,21,20,22,21,21,20,22,20,20,24,20,19,21,21,22,25,21,22,25,20,24,20,21,20,20,31,20,22,22,21,22,21,21,21,21,20,21,25,21,24,20,21,20,20,18,21,19,21,20,21,20,21,20,18,22,22,24,19,20,20,17,19,20,20,20,20,19,19,22,35,18,19,21],[3.58333333333333,2.91666666666667,3.5,3.5,3.66666666666667,4.75,3.83333333333333,3.25,4.33333333333333,4,3.58333333333333,3.83333333333333,4.25,3.33333333333333,4.16666666666667,3.66666666666667,4.08333333333333,3.5,4.08333333333333,4,3.91666666666667,4,4,3.66666666666667,3.66666666666667,4.41666666666667,3.91666666666667,3.75,3.25,3.58333333333333,4.91666666666667,3.58333333333333,2.91666666666667,3.66666666666667,4.5,4.08333333333333,3.83333333333333,3.25,2.33333333333333,3.33333333333333,4.08333333333333,2.91666666666667,3.33333333333333,3.83333333333333,3.66666666666667,4.66666666666667,3.75,3.41666666666667,4.16666666666667,2.91666666666667,4.16666666666667,3.58333333333333,2.83333333333333,4,2.91666666666667,3,4.08333333333333,2.91666666666667,3.5,4.33333333333333,4.25,3.41666666666667,3.08333333333333,4.58333333333333,3.41666666666667,3.41666666666667,3.41666666666667,3.58333333333333,1.58333333333333,3.33333333333333,4.33333333333333,4.41666666666667,4.83333333333333,3.08333333333333,3,4.08333333333333,4.08333333333333,3.75,3.08333333333333,4.75,4.25,4.16666666666667,4.41666666666667,3.83333333333333,3.33333333333333,3.16666666666667,3.16666666666667,3.83333333333333,4.25,3.83333333333333,3.66666666666667,3.83333333333333,3.83333333333333,3.83333333333333,3.66666666666667,4.33333333333333,3.75,4.16666666666667,4,4,4.58333333333333,3.66666666666667,3.66666666666667,3.83333333333333,2.58333333333333,3.5,3.08333333333333,4.25,3.16666666666667,3.08333333333333,4.16666666666667,2.25,3.33333333333333,3.08333333333333,2.75,3.25,4,3.58333333333333,4.08333333333333,4.25,3.41666666666667,3.08333333333333,3.5,3.66666666666667,4.25,4.25,3.83333333333333,4.41666666666667,3.5,3.58333333333333,3.66666666666667,2.08333333333333,4.25,3.58333333333333,4,3.33333333333333,3.5,3.16666666666667,3.58333333333333,3.41666666666667,4.25,3.25,4.41666666666667,3.25,3.91666666666667,3.58333333333333,4.5,3.58333333333333,3.66666666666667,2.58333333333333,4.16666666666667,3.25,4.33333333333333,3.91666666666667,2.66666666666667,3.08333333333333,3.75,4.16666666666667,4.16666666666667,3.25,4.08333333333333,2.91666666666667,3.83333333333333,3.16666666666667,3.41666666666667,4.08333333333333],[3.375,2.75,3.625,3.125,3.625,3.625,2.25,4,4.25,3.5,3.625,4.75,3.625,3.5,1.75,3.875,1.375,3.25,3,3.75,2.625,2.375,3.625,2.75,1.75,3.25,4,3.625,2.875,3,1.625,3.25,3.5,3,3.25,1.875,4.375,3.625,2.5,1.25,4,3,2.5,4.875,5,4.375,3.25,4,3.125,2.5,3.125,3.25,2.125,2.75,2.375,3.125,4,4,2.25,3.25,3.625,3.625,2.5,1.875,2,1.875,4,2.875,3.875,2.5,2.75,4.5,3.375,2.625,4.125,2.625,2.25,2.75,3,1.625,1.875,3.375,3.75,2.125,2.375,2.75,3.125,3.5,2.625,3.375,2.25,3,4,3.5,2.625,2.5,3.75,3.625,4.125,4.375,2.625,4,2.75,2.75,1.375,2.25,3.625,3.75,4,3.125,3.25,2.125,2.875,1.5,2.5,3.25,3.625,3.875,3.875,2.375,3,3.375,2.75,4.5,2.625,2.75,3.25,4.125,3.375,2.75,4.125,3.25,2.875,2.875,2.375,3.875,2.125,4,3.25,2.625,2.75,4,3,3.375,3.875,3.25,3.375,4.125,3.5,2,3.625,3.375,2.125,4.625,2.5,2.875,2.75,4,2.375,3.875,3.375,1.75,3,2.625,2.625,3.375],[2.58333333333333,3.16666666666667,2.25,2.25,2.83333333333333,2.41666666666667,1.91666666666667,2.83333333333333,2.16666666666667,3,2.66666666666667,2.41666666666667,2.25,2.75,2.33333333333333,2.33333333333333,2.91666666666667,2.5,3.75,2.75,2.33333333333333,2.41666666666667,3,2.41666666666667,2.83333333333333,3.16666666666667,3,2,3.5,3.75,2.5,2.08333333333333,2.41666666666667,2.58333333333333,1.58333333333333,2.83333333333333,1.83333333333333,2.41666666666667,3.25,3.41666666666667,3.41666666666667,3.16666666666667,3.5,2.66666666666667,2.41666666666667,3.58333333333333,2.08333333333333,3.75,2.91666666666667,2.91666666666667,2.41666666666667,3,3.41666666666667,2.91666666666667,3.25,3.25,2.33333333333333,3.25,2.5,1.75,2.25,2.08333333333333,2.83333333333333,2.83333333333333,2.41666666666667,2.25,2.83333333333333,2.25,1.83333333333333,2.91666666666667,2.91666666666667,2.08333333333333,2.33333333333333,2.41666666666667,2.75,3.25,1.75,2.58333333333333,3.33333333333333,2.83333333333333,2.5,2.41666666666667,2.41666666666667,2.58333333333333,3,2,3.41666666666667,2.83333333333333,2.25,2.75,3.91666666666667,2.33333333333333,2.75,2.75,2.91666666666667,2.08333333333333,3.66666666666667,2.83333333333333,3.41666666666667,1.58333333333333,2.91666666666667,3,2.91666666666667,2.66666666666667,3,2.75,3.08333333333333,2.5,2.33333333333333,3,3,4,3.25,3.5,3.5,3.83333333333333,2.91666666666667,2.16666666666667,1.66666666666667,2.08333333333333,2.83333333333333,3.41666666666667,3.33333333333333,2.58333333333333,2.83333333333333,3.33333333333333,3,2.58333333333333,2.41666666666667,3.58333333333333,2.08333333333333,4.33333333333333,2.66666666666667,3,2.66666666666667,2.16666666666667,2.66666666666667,2.25,2.66666666666667,3.33333333333333,3.5,2.75,2,2.83333333333333,3.5,2.5,3.16666666666667,3.08333333333333,2.91666666666667,3.16666666666667,2.5,3.83333333333333,2.25,3.41666666666667,3.75,3,2.58333333333333,3.33333333333333,2.83333333333333,3,2.83333333333333,3.16666666666667,2.75,3.41666666666667,3,2.66666666666667]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th> <\/th>\n      <th>gender<\/th>\n      <th>points<\/th>\n      <th>attitude<\/th>\n      <th>age<\/th>\n      <th>deep<\/th>\n      <th>stra<\/th>\n      <th>surf<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"columnDefs":[{"targets":[1,2,3,4,5,6,7],"render":"function(data, type, row, meta) {\nreturn type === 'display' && data.toString().length > 5 ?\n'<span title=\"' + data.toString() + '\">' + data.toString().substr(0, 5) + '...<\/span>' : data.toString();\n}"},{"className":"dt-right","targets":[2,3,4,5,6,7]},{"orderable":false,"targets":0}],"order":[],"autoWidth":false,"orderClasses":false},"callback":"function(table) {\ntable.page(0).draw(false);\n}"},"evals":["options.columnDefs.0.render","callback"],"jsHooks":[]}</script>
</div>
</div>
<div id="graphical-overview" class="section level2">
<h2>2: Graphical overview</h2>
<p>Now we wish to perform exploratory (visual) analysis on the data to determine which factors might predict success in the exam among students.</p>
<p>Instead of printing out a rather complex scatter plot matrix including all variables at once, I chose to have separate graphs for each variable.</p>
<p>Below you can see a convenience function that I wrote for creating the individual graphs.</p>
<pre class="r"><code>library(ggplot2)
library(ggExtra)
library(ggpubr)


#A convenience function for creating informative scatter plots.
createScatterPlot &lt;- function(predictor,displayName){

  
 
  #Use custom color scheme for the graphs.
  plotColors &lt;- c(&quot;F&quot; = &quot;red&quot;, &quot;M&quot; = &quot;blue&quot;, &quot;Combined&quot; = &quot;black&quot;)
  
  #Create the plot with gender as contrast and place the legend at the bottom to save horizontal space.
  scatterPlot &lt;- ggplot(analysisDataset, aes(x = predictor, y = points,col = gender, shape=gender,colour=plotColors))+theme(legend.position=&quot;bottom&quot;)
  
  #Add scatterplot points and prevent point stacking with jitter. Also suppress the separate legend for the gender specific point shapes.
  scatterPlot &lt;- scatterPlot + geom_point(position = position_jitter(width = 0.5, height = 0.5))+guides(shape=FALSE)
  
  #Draw the regression lines for both groups (male and female) and print the respective Pearson correlation coefficients
  scatterPlot &lt;- scatterPlot + geom_smooth(method=&quot;lm&quot;, se=FALSE)+stat_cor(method = &quot;pearson&quot;, p.accuracy = 0.001, r.accuracy = 0.01, position = position_nudge(x=0,y=4.4))
  
  #Change the aesthetics mappings a little bit to print a regression line for data in both groups
  scatterPlot &lt;- scatterPlot + geom_smooth(mapping=aes(predictor,points,colour = &quot;Combined&quot;),method = &quot;lm&quot;, se=FALSE, data = analysisDataset,inherit.aes =FALSE)
  #Print the Pearson correlation coefficient for both groups. Also adjust the text position so that it doesn&#39;t overlap with the previously printed text.
  scatterPlot &lt;- scatterPlot + stat_cor(mapping=aes(predictor,points,colour = &quot;Combined&quot;),method = &quot;pearson&quot;, p.accuracy = 0.001, r.accuracy = 0.01,inherit.aes = FALSE,position = position_nudge(x=0,y=2))
  
  #Print the x- and y-axis labels and suppress the superfluous legend label
  scatterPlot &lt;- scatterPlot + labs(x = displayName,y = &quot;Exam points&quot;,colour = &quot;&quot;)
  
  #Apply our custom color scheme and readable data labels
  scatterPlot &lt;- scatterPlot + scale_color_manual(values =plotColors, labels=c(&quot;Combined&quot;,&quot;Female&quot;, &quot;Male&quot;))
  
  #Apply a title for the graph
  scatterPlot &lt;- scatterPlot + ggtitle(paste(displayName, &quot;versus exam points&quot;, sep = &quot; &quot;))
  
  #Add marginal boxplots for visualizing outliers, distribution, and group differences
  scatterPlot &lt;- ggMarginal(p=scatterPlot,type=&quot;boxplot&quot;,size = 6,groupColour = TRUE, groupFill = TRUE)
  
  #Print the plot.
  scatterPlot
  
  
}</code></pre>
<hr />
<p>Here you can inspect each graph under its corresponding tab.</p>
<hr />
<div id="section-1" class="section level3 tabset tabset-fade">
<h3></h3>
<div id="attitude" class="section level4">
<h4><strong>Attitude</strong></h4>
<pre class="r"><code>#Draw the plot using the previously created convenience function
createScatterPlot(analysisDataset$attitude, displayName=&quot;Attitude&quot;)</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-4-1.png" width="100%" /></p>
<hr />
<div id="interpretation" class="section level5">
<h5>Interpretation</h5>
<p>Based on this graph, there seems to be a considerable positive correlation between attitude and exam points. Seemingly there may also be minor differences in the distribution of attitude between genders. This should be taken into account if/when any difference is observed between the genders in exam points.</p>
</div>
</div>
<div id="age" class="section level4">
<h4><strong>Age</strong></h4>
<pre class="r"><code>createScatterPlot(analysisDataset$age,displayName=&quot;Age&quot;)</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-5-1.png" width="100%" /></p>
<hr />
<div id="interpretation-1" class="section level5">
<h5>Interpretation</h5>
<p>No significant correlations here. The two outliers in the male group cause a trending result which is sure to vanish by excluding these outliers.</p>
</div>
</div>
<div id="gender" class="section level4">
<h4><strong>Gender</strong></h4>
<pre class="r"><code>#For a class variable like the gender we want something a little bit different
#Create a box plot with gender vs exam points
boxPlot &lt;- ggplot(analysisDataset, aes(x = gender, y = points, color=gender, fill=gender))+theme(legend.position=&quot;none&quot;)
boxPlot &lt;- boxPlot + geom_boxplot(outlier.colour=&quot;black&quot;, outlier.shape=16, outlier.size=2, notch=FALSE)

#Adjust outline color
boxPlot &lt;- boxPlot + scale_color_manual(values=c(&quot;black&quot;,&quot;black&quot;))

#Adjust fill color
boxPlot &lt;- boxPlot + scale_fill_manual(values=c(&quot;red&quot;,&quot;blue&quot;))

#Set proper lables for both axes
boxPlot &lt;- boxPlot + labs(x = &quot;Gender&quot;,y = &quot;Exam points&quot;, fill = &quot;&quot;)

#Set the graph title
boxPlot &lt;- boxPlot + ggtitle(&quot;Gender versus exam points&quot;)

#Print the plot
boxPlot</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-6-1.png" width="100%" /></p>
<hr />
<div id="interpretation-2" class="section level5">
<h5>Interpretation</h5>
<p>Based on a visual inspection, there’s likely no major differences in exam points based on gender.</p>
</div>
</div>
<div id="deep-learning" class="section level4">
<h4><strong>Deep learning</strong></h4>
<pre class="r"><code>createScatterPlot(analysisDataset$deep,displayName=&quot;Deep learning&quot;)</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-7-1.png" width="100%" /></p>
<hr />
<div id="interpretation-3" class="section level5">
<h5>Interpretation</h5>
<p>No significant correlation here.</p>
</div>
</div>
<div id="superficial-learning" class="section level4">
<h4><strong>Superficial learning</strong></h4>
<pre class="r"><code>createScatterPlot(analysisDataset$surf,displayName=&quot;Superficial learning&quot;)</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-8-1.png" width="100%" /></p>
<hr />
<div id="interpretation-4" class="section level5">
<h5>Interpretation</h5>
<p>Overall trending negative correlation.</p>
</div>
</div>
<div id="strategic-learning" class="section level4">
<h4><strong>Strategic learning</strong></h4>
<pre class="r"><code>createScatterPlot(analysisDataset$stra,displayName=&quot;Strategic learning&quot;)</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-9-1.png" width="100%" /></p>
<hr />
<div id="interpretation-5" class="section level5">
<h5>Interpretation</h5>
<p>Overall trending positive correlation.</p>
</div>
</div>
</div>
</div>
<div id="building-the-regression-model" class="section level2">
<h2>3: Building the regression model</h2>
<p>Based on the exploratory analysis, attitude is obviously the most promising predictor for exam points. The next most promising predictors seem to be strategic and surface learning approaches. Well choose these three for our multiple regression model.</p>
<pre class="r"><code>#Create the regression model
multipleRegression &lt;- lm(points ~ attitude + stra + surf, data = analysisDataset)

#Print a summary of the model
summary(multipleRegression)</code></pre>
<pre><code>## 
## Call:
## lm(formula = points ~ attitude + stra + surf, data = analysisDataset)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -17.1550  -3.4346   0.5156   3.6401  10.8952 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  11.0171     3.6837   2.991  0.00322 ** 
## attitude      3.3952     0.5741   5.913 1.93e-08 ***
## stra          0.8531     0.5416   1.575  0.11716    
## surf         -0.5861     0.8014  -0.731  0.46563    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.296 on 162 degrees of freedom
## Multiple R-squared:  0.2074, Adjusted R-squared:  0.1927 
## F-statistic: 14.13 on 3 and 162 DF,  p-value: 3.156e-08</code></pre>
<hr />
<div id="stepwise-selection" class="section level3">
<h3>Stepwise selection</h3>
<p>Next we wish to optimize our model by backward stepwise selection. Drop out any predictors with a p&gt;0.05.</p>
<hr />
<pre class="r"><code>#Drop out independent variables in a stepwise manner as long as their individual p&gt;0.05
#The k for critical p=0.05 is taken from the chi-squared distribution: qchisq(p=0.05,df=1,lower.tail=FALSE).

finalModel=step(object= multipleRegression, direction=&quot;backward&quot;, k = qchisq(p=0.05,df=1,lower.tail=FALSE))</code></pre>
<pre><code>## Start:  AIC=564.77
## points ~ attitude + stra + surf
## 
##            Df Sum of Sq    RSS    AIC
## - surf      1     15.00 4559.4 561.47
## - stra      1     69.61 4614.0 563.45
## &lt;none&gt;                  4544.4 564.77
## - attitude  1    980.95 5525.3 593.37
## 
## Step:  AIC=561.47
## points ~ attitude + stra
## 
##            Df Sum of Sq    RSS    AIC
## - stra      1     81.74 4641.1 560.58
## &lt;none&gt;                  4559.4 561.47
## - attitude  1   1051.89 5611.3 592.09
## 
## Step:  AIC=560.58
## points ~ attitude
## 
##            Df Sum of Sq    RSS    AIC
## &lt;none&gt;                  4641.1 560.58
## - attitude  1    1092.6 5733.7 591.83</code></pre>
<pre class="r"><code>summary(finalModel)</code></pre>
<pre><code>## 
## Call:
## lm(formula = points ~ attitude, data = analysisDataset)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.9763  -3.2119   0.4339   4.1534  10.6645 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  11.6372     1.8303   6.358 1.95e-09 ***
## attitude      3.5255     0.5674   6.214 4.12e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.32 on 164 degrees of freedom
## Multiple R-squared:  0.1906, Adjusted R-squared:  0.1856 
## F-statistic: 38.61 on 1 and 164 DF,  p-value: 4.119e-09</code></pre>
<hr />
</div>
<div id="final-model" class="section level3">
<h3>Final model</h3>
<p>The resulting model is points ~ attitude. I.e., neither stra or surf predicted the exam points at a statistically significant (p&lt;0.05) level and were dropped out.</p>
</div>
</div>
<div id="model-interpretation" class="section level2">
<h2>4: Model interpretation</h2>
<p>Re-print the model summary:</p>
<pre class="r"><code>summary(finalModel)</code></pre>
<pre><code>## 
## Call:
## lm(formula = points ~ attitude, data = analysisDataset)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -16.9763  -3.2119   0.4339   4.1534  10.6645 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  11.6372     1.8303   6.358 1.95e-09 ***
## attitude      3.5255     0.5674   6.214 4.12e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 5.32 on 164 degrees of freedom
## Multiple R-squared:  0.1906, Adjusted R-squared:  0.1856 
## F-statistic: 38.61 on 1 and 164 DF,  p-value: 4.119e-09</code></pre>
<p>From this model we can see that the predicted score in the exam goes up 3.53 points (95% CI: 2.41 - 4.64, p &lt; 0.001) points for every increase of one in the student’s attitude. The multiple R squared is actually equal to “singular” R squared in this case as the final model is no longer a multiple regression due to dropping out the insignificant predictors</p>
<p>The resulting regression model written out with scalar values is: points = 3.53 * attitude + 11.64</p>
<p>The R squared signifies the proportion of variance in exam points that our model is able to explain. In this case 19%.</p>
</div>
<div id="model-validation" class="section level2">
<h2>5: Model validation</h2>
<p>Print out the requested diagnostic plots:</p>
<pre class="r"><code>plot(finalModel,which = c(1,2,5))</code></pre>
<p><img src="chapter2_files/figure-html/unnamed-chunk-13-1.png" width="100%" /><img src="chapter2_files/figure-html/unnamed-chunk-13-2.png" width="100%" /><img src="chapter2_files/figure-html/unnamed-chunk-13-3.png" width="100%" /></p>
<hr />
<p>Evaluation of assumptions:</p>
<ol style="list-style-type: decimal">
<li>Linearity of functional form:
<ul>
<li>Satisfied. Inspecting the residuals <em>versus</em> fitted graph below, there is no pattern in the mean observations across the x-axis.</li>
</ul></li>
<li>Mean of residual approximately zero:
<ul>
<li>Satisfied. Inspecting the residuals <em>versus</em> fitted graph below, the residuals seem evenly distributed around y=0.</li>
</ul></li>
<li>Homoscedasticity of residuals:
<ul>
<li>Satisfied. Inspecting the residuals <em>versus</em> fitted graph below, a “shotgun pattern” can be observed (i.e. there is no obvious pattern in the graph indicating difference in variance over x-axis).</li>
</ul></li>
<li>Normal distribution of residuals:
<ul>
<li>Satisfied. This is evident inspecting the Q-Q-plot of the standardized residuals.</li>
</ul></li>
<li>No overtly influential observations/outliers:
<ul>
<li>Satisfied. Cooks’s distances for all observations are very small. Even though there are a few observations with standardized residuals near -3 they are of no serious consequence for the model estimate for attitude as evidenced by theis Cook’s distances. However, if the intercept is of interest, these observations could potentially have an affect on the estimate for the intercept.</li>
</ul></li>
</ol>
</div>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
